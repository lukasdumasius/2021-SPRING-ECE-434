{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE/CS 434 | MP4: AoA\n",
    "<br />\n",
    "<nav>\n",
    "    <span class=\"alert alert-block alert-warning\">Due at 5PM xxxx 2021 on Gradescope</span> |\n",
    "    <a href=\"https://www.gradescope.com/courses/223105\">Gradescope</a> | \n",
    "    <a href=\"https://courses.grainger.illinois.edu/cs434/sp2021/\">Course Website</a> | \n",
    "    <a href=\"http://piazza.com/illinois/spring2021/csece434\">Piazza</a>\n",
    "</nav><br> \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><h2>This file will <u>NOT</u> be used for grading. It is a scratch space for your own experimentation & analysis.</h2></div>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.signal as sig\n",
    "\n",
    "plt.style.use(\"seaborn\") # This sets the matplotlib color scheme to something more soothing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-133, 139, -41, -50, -41, -13, -65, 139]\n",
      "index14\n",
      "(3, 1)\n",
      "estimated location= (3, 1)\n"
     ]
    }
   ],
   "source": [
    "array_locs = np.genfromtxt ('dataset0/config.csv', delimiter=\",\")\n",
    "expected_user_loc = np.array((3.0, 1.0))\n",
    "test_folder = 'dataset0'\n",
    "\n",
    "# [(0.023, 0.0399), (0.0461, 0), (0.023, -0.0399), (-0.023, -0.0399), (-0.0461, 0), (-0.023, 0.0399)]\n",
    "\n",
    "array_MIC_OFFSETS = np.array([(0.023, 0.0399), (0.0461, 0), (0.023, -0.0399), (-0.023, -0.0399), (-0.0461, 0), (-0.023, 0.0399)])\n",
    "\n",
    "list_dataframes_csvfiles = [] # list of files\n",
    "\n",
    "# changed mic_num -> mic_num_general to avoid ambiguity - this means the mic array num (which alexa device we're talking about)\n",
    "for mic_num_general in np.arange(8):\n",
    "    list_dataframes_csvfiles.append( pd.read_csv(\n",
    "        \"{}/{}.csv\".format(test_folder, mic_num_general), \n",
    "        header=None\n",
    "    ) )\n",
    "\n",
    "\n",
    "list_mics_og_samples = [] # first index - general mic (alexa), second - specific mic, third - specific sample\n",
    "                          # similar accessing for array_locs: array_locs[general_mic_num][0=x, 1=y]\n",
    "\n",
    "for csvfile_general_mic in np.arange( len(list_dataframes_csvfiles) ):\n",
    "    list_mics_og_samples.append([])\n",
    "    for specific_mic in np.arange( list_dataframes_csvfiles[csvfile_general_mic].shape[1] ):\n",
    "        list_mics_og_samples[csvfile_general_mic].append(list_dataframes_csvfiles[csvfile_general_mic][specific_mic])\n",
    "        \n",
    "# switching list_mics_og_samples to a numpy array for faster processing when shifting later\n",
    "array_mics_og_samples = np.array(list_mics_og_samples)\n",
    "\n",
    "\n",
    "user_distance = 100         # assume user is 100m away for far field assumption\n",
    "num_local_mics = 6          # 6 local mics in each \"General mic array/location\"\n",
    "speed_of_sound_ms = 340     # speed of sound is ~ 340 m/s\n",
    "sampling_frequency = 16000  # mic sampling frequency\n",
    "num_samples = 24000\n",
    "num_of_general_mic_arrays = 8\n",
    "###################### start - generate_aoas ######################\n",
    "def generate_aoas():\n",
    "    \n",
    "    list_final_correlations = [] # list of lists. each inner list indices correspond in order from -180 to 179 degrees\n",
    "                                 # each outer list corresponds to each general mic array (alexa device)\n",
    "    for curr_general_mic_array in np.arange(num_of_general_mic_arrays):\n",
    "\n",
    "        list_curr_overall_correlations = []      # indices correspond in order from -180 to 179 degrees\n",
    "        for curr_angle in np.arange(-180, 180):      #  np.arange returns [start,stop) (non-inclusive on stop) but thats not a problem because\n",
    "                                                     #  I reckon its better not to have 2 equal angles (-180 == 180)\n",
    "\n",
    "            tuple_general_mic_array_location = tuple( (array_locs[curr_general_mic_array][0], array_locs[curr_general_mic_array][1]) )  #0=x, 1=y  #****\n",
    "            list_tuples_local_mic_locations = []       # first index - local mic number, second index - 0=x, 1=y\n",
    "\n",
    "            for local_mic_num in np.arange(num_local_mics):\n",
    "                list_tuples_local_mic_locations.append(tuple( (tuple_general_mic_array_location[0] + array_MIC_OFFSETS[local_mic_num][0],\n",
    "                                                              tuple_general_mic_array_location[1] + array_MIC_OFFSETS[local_mic_num][1]) ))\n",
    "\n",
    "\n",
    "            tuple_user_location_assumed = tuple( (tuple_general_mic_array_location[0] + math.cos(math.radians(curr_angle))*user_distance, \n",
    "                                           tuple_general_mic_array_location[1] + math.sin(math.radians(curr_angle))*user_distance) )\n",
    "\n",
    "            list_distances_to_local_mics = []                 # d0, d1 ... d5 - contains distance to each local mic from assumed user location\n",
    "            for local_mic_num in np.arange(num_local_mics):\n",
    "                list_distances_to_local_mics.append( math.dist(tuple_user_location_assumed, list_tuples_local_mic_locations[local_mic_num]) )\n",
    "\n",
    "\n",
    "            list_diff_distances_to_local_mics = []      # contains distance d1-d0, d2-d0, ... d5-d0\n",
    "\n",
    "            for local_mic_num in np.arange(num_local_mics):\n",
    "                if(local_mic_num > 0):\n",
    "                    list_diff_distances_to_local_mics.append(list_distances_to_local_mics[local_mic_num] - list_distances_to_local_mics[0])\n",
    "\n",
    "\n",
    "            # print(list_diff_distances_to_local_mics) # debugging\n",
    "\n",
    "            list_time_delays_to_local_mics = []        # contains differences in seconds t1-t0, t2-t0, ... t5-t0\n",
    "\n",
    "            for distance_diff in list_diff_distances_to_local_mics:\n",
    "                list_time_delays_to_local_mics.append(distance_diff/speed_of_sound_ms)\n",
    "\n",
    "            list_sample_delays_to_local_mics = []     # contains differences in samples, so # of samples mic1 lags mic0, mic2 lags mic0... mic5 lags mic0\n",
    "\n",
    "            for time_diff in list_time_delays_to_local_mics:\n",
    "                list_sample_delays_to_local_mics.append(time_diff*sampling_frequency)\n",
    "\n",
    "\n",
    "            # print(list_sample_delays_to_local_mics)  # debugging\n",
    "\n",
    "            array_mics_adjusted_samples = np.empty((num_local_mics, num_samples))    # 1st index - specific mic 0->5, 2nd index - sample index 0->23999\n",
    "                                                                                     # 0 - empty, 1 - mic1 adjusted, ... 5 - mic5 adjusted \n",
    "\n",
    "            #for local_mic_num in np.arange(num_local_mics):\n",
    "            #    list_mics_adjusted_samples.append([])                          # append an empty list for each local mic\n",
    "            #    list_mics_adjusted_samples[local_mic_num] = [0] * num_samples  #append 24000 0s\n",
    "\n",
    "            for local_mic_num in np.arange(1, num_local_mics): # 1-> 5\n",
    "                #for i in np.arange(num_samples):\n",
    "                    #if( (i - int(round(list_sample_delays_to_local_mics[local_mic_num-1]))) >= 0 and (i - int(round(list_sample_delays_to_local_mics[local_mic_num-1]))) < num_samples):\n",
    "                        #list_mics_adjusted_samples[local_mic_num][i - int(round(list_sample_delays_to_local_mics[local_mic_num-1]))] = list_mics_og_samples[curr_general_mic_array][local_mic_num][i]   # **** ADJUST 0 TO GENERAL ARRAY LATER\n",
    "                array_mics_adjusted_samples[local_mic_num] = np.roll(array_mics_og_samples[curr_general_mic_array][local_mic_num], -int(round(list_sample_delays_to_local_mics[local_mic_num-1])))\n",
    "\n",
    "            curr_correlations = []             # indx 0 - empty, indx 1 - correlation mic1 to mic0, indx 2 - correlation mic2 to mic0, indx 5 - correlation mic5 to mic0\n",
    "            for local_mic_num in np.arange(num_local_mics):\n",
    "                curr_correlations.append(0)    # fill with 0s\n",
    "            for local_mic_num in np.arange(1, num_local_mics):   # correlate each mic's (1->5) adjusted samples with mic0\n",
    "                curr_correlations[local_mic_num] = sig.correlate(array_mics_og_samples[curr_general_mic_array][0], array_mics_adjusted_samples[local_mic_num], mode = 'valid')[0]  #adjust (first index) so that its not 0 but correct general array****\n",
    "\n",
    "            curr_correlation_sum = 0\n",
    "\n",
    "            for each_mic_correlation in curr_correlations:\n",
    "                curr_correlation_sum += each_mic_correlation\n",
    "\n",
    "            list_curr_overall_correlations.append(curr_correlation_sum)\n",
    "\n",
    "\n",
    "        list_final_correlations.append(list_curr_overall_correlations)\n",
    "\n",
    "    # print(list_final_correlations[0]) # debugging\n",
    "\n",
    "    list_aoas = [] # list of aoas in degrees in order of general mic arrays / alexa devices (0 -> 7)\n",
    "\n",
    "    for j in np.arange(num_of_general_mic_arrays):\n",
    "        list_aoas.append( list_final_correlations[j].index(max(list_final_correlations[j])) - 180 )     # subtract 180 because each index is in order corresponding -180 -> 179 degrees\n",
    "    \n",
    "    #print(list_aoas)  # debugging,  this is what we want to return\n",
    "\n",
    "    #### graphing stuff - can comment out ###\n",
    "    #x_axis = []\n",
    "    #for j in np.arange(len(list_final_correlations[0])):\n",
    "    #    x_axis.append(j-180)\n",
    "\n",
    "    #fig, ax = plt.subplots(2,4, figsize=(20,10))\n",
    "    #ax = ax.flatten()\n",
    "    #for j in np.arange(8):\n",
    "    #    ax[j].set_title(\"alexa number {}\".format(str(j)))\n",
    "    #    ax[j].plot(x_axis, list_final_correlations[j])\n",
    "    #### graphing stuff - can comment out ###\n",
    "    \n",
    "    return list_aoas\n",
    "###################### end - generate_aoas ######################\n",
    "\n",
    "###################### start - triangulation ######################\n",
    "\n",
    "\n",
    "                                      # takes input of list of generated aoas for general mic arrays/alexas  0 -> 7\n",
    "def triangulation(list_input_aoas):   # also uses \"array_locs\"  'global' variable from above  \n",
    "    \n",
    "    def distance_to_line(point_of_interest, line_point_1, line_point_2):  # all inputs are tuples of points\n",
    "        # abs((x2-x1)*(y1-y0) - (x1-x0)*(y2-y1)) / np.sqrt(np.square(x2-x1) + np.square(y2-y1))\n",
    "        return ((abs((line_point_2[0]-line_point_1[0])*(line_point_1[1]-point_of_interest[1])-(line_point_1[0]-point_of_interest[0])*(line_point_2[1]-line_point_1[1]))) /  (np.sqrt(np.square(line_point_2[0]-line_point_1[0]) + np.square(line_point_2[1] - line_point_1[1]))))\n",
    "    \n",
    "    assumed_distance_between_points = 10  # this is the distance (m) between the original general mic array point and generated point\n",
    "    \n",
    "    list_tuples_points_generated_lines = []  # list of lists of 2 tuples each\n",
    "                                             # first index- which general mic array set of points we're interested in\n",
    "                                             # second index- which point (first (original) or second (generated) )\n",
    "                                             # third index- 0=x, 1=y\n",
    "    for general_mic_num in np.arange(num_of_general_mic_arrays):\n",
    "        list_curr_points = [] # list of two tuples of the 2 current points\n",
    "        tuple_point_one = tuple( (array_locs[general_mic_num][0], array_locs[general_mic_num][1])  )\n",
    "        \n",
    "        generated_x_coord = array_locs[general_mic_num][0] + assumed_distance_between_points*math.cos(math.radians(list_input_aoas[general_mic_num]))\n",
    "        generated_y_coord = array_locs[general_mic_num][1] + assumed_distance_between_points*math.sin(math.radians(list_input_aoas[general_mic_num]))\n",
    "        tuple_point_two = tuple( (generated_x_coord, generated_y_coord) )\n",
    "        \n",
    "        list_curr_points.append(tuple_point_one)\n",
    "        list_curr_points.append(tuple_point_two)\n",
    "        \n",
    "        list_tuples_points_generated_lines.append(list_curr_points)\n",
    "        \n",
    "        \n",
    "    x_grid_search_max = int(math.ceil(max(array_locs[:,0])))\n",
    "    y_grid_search_max = int(math.ceil(max(array_locs[:,1])))\n",
    "    x_grid_search_min = int(math.ceil(min(array_locs[:,0])))\n",
    "    y_grid_search_min = int(math.ceil(min(array_locs[:,1])))\n",
    "    \n",
    "    x_grid_search_max = 10\n",
    "    y_grid_search_max = 10\n",
    "    x_grid_search_min = 0\n",
    "    y_grid_search_min = 0\n",
    "    \n",
    "    x_grid_search_width = x_grid_search_max - x_grid_search_min + 1\n",
    "    y_grid_search_width = y_grid_search_max - y_grid_search_min + 1\n",
    "    \n",
    "    array_point_distances = np.empty((y_grid_search_width, x_grid_search_width))\n",
    "    \n",
    "    for y_ind in np.arange(y_grid_search_min, y_grid_search_max+1):         # + 1 because numpy.arange() is non-inclusive on stop\n",
    "        for x_ind in np.arange(x_grid_search_min, x_grid_search_max + 1):   # + 1 because numpy.arange() is non-inclusive on stop\n",
    "            curr_distance_sum = 0\n",
    "            for general_mic_num in np.arange(num_of_general_mic_arrays):      # in other words, compare distance to each line at this current point\n",
    "                curr_distance_sum += distance_to_line((x_ind, y_ind), list_tuples_points_generated_lines[general_mic_num][0], list_tuples_points_generated_lines[general_mic_num][1]) # returns just one value\n",
    "            array_point_distances[y_ind-y_grid_search_min][x_ind-x_grid_search_min] = curr_distance_sum\n",
    "            \n",
    "\n",
    "    \n",
    "    user_estimated_location_index = np.argmin(array_point_distances)\n",
    "    print(\"index\" + str(user_estimated_location_index))\n",
    "    \n",
    "    user_estimated_location_index_row = math.floor(user_estimated_location_index/array_point_distances.shape[1])\n",
    "    user_estimated_location_index_col = user_estimated_location_index - user_estimated_location_index_row*array_point_distances.shape[1]\n",
    "    \n",
    "    #print(array_point_distances)\n",
    "    #print(\"x grid search min: \" + str(x_grid_search_min))\n",
    "    #print(\"y grid search min: \" + str(y_grid_search_min))\n",
    "    \n",
    "    \n",
    "    return user_estimated_location_index_col+x_grid_search_min, user_estimated_location_index_row+y_grid_search_min\n",
    "    \n",
    "###################### end - triangulation ######################\n",
    "\n",
    "\n",
    "list_generated_aoas = generate_aoas()\n",
    "print(list_generated_aoas)\n",
    "estimate = triangulation(list_generated_aoas)\n",
    "print(estimate)\n",
    "print(\"estimated location= \" + str(estimate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
